---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

Most recent publications on [Google Scholar](https://scholar.google.com/citations?user=BIFGeoUAAAAJ&hl=en).  
\* denotes co-first authors
<!-- $^\dagger$ denotes corresponding author/main advisor -->

**B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners**  
Weihao Zeng\*, Yuzhen Huang\*, Lulu Zhao, Yijun Wang, Zifei Shan, *<ins>Junxian He</ins>*  
Preprint 2024. [[arxiv]](https://arxiv.org/abs/2412.17256) [[github]](https://github.com/hkust-nlp/B-STaR)

**Diving into Self-Evolving Training for Multimodal Reasoning**  
Wei Liu\*, Junlong Li\*, Xiwen Zhang, Fan Zhou, Yu Cheng, *<ins>Junxian He</ins>*  
Preprint 2024. [[arxiv]](https://arxiv.org/abs/2412.17451) [[github]](https://github.com/hkust-nlp/mstar)

**Non-myopic Generation of Language Models for Reasoning and Planning**  
Chang Ma, Haiteng Zhao, Junlei Zhang, *<ins>Junxian He</ins>*, Lingpeng Kong  
Preprint 2024. [[arxiv]](https://arxiv.org/abs/2410.17195)

**AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents**  
Chang Ma\*, Junlei Zhang\*, Zhihao Zhu\*, Cheng Yang\*, Yujiu Yang, Yaohui Jin, Zhenzhong Lan, Lingpeng Kong, *<ins>Junxian He</ins>*  
NeurIPS 2024 (Datasets and Benchmarks Track). [[arxiv]](https://arxiv.org/abs/2401.13178) [[github]](https://github.com/hkust-nlp/AgentBoard)  
<span style="color:red"><i>Oral</i></span>

**DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving**  
Yuxuan Tong, Xiwen Zhang, Rui Wang, Ruidong Wu, *<ins>Junxian He</ins>*   
NeurIPS 2024. [[arxiv]](https://arxiv.org/abs/2407.13690) [[github]](https://github.com/hkust-nlp/dart-math)

**Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in LLMs**  
Zhiyuan Hu, Chumin Liu, Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan Luu, *<ins>Junxian He</ins>*, Pang Wei Koh, Bryan Hooi  
NeurIPS 2024. [[arxiv]](https://arxiv.org/abs/2402.03271)

**On the Universal Truthfulness Hyperplane Inside LLMs**  
Junteng Liu, Shiqi Chen, Yu Cheng, *<ins>Junxian He</ins>*  
EMNLP 2024. [[arxiv]](https://arxiv.org/abs/2407.08582)

**Belief Revision: The Adaptability of Large Language Models Reasoning**  
Bryan Wilie, Samuel Cahyawijaya, Etsuko Ishii, *<ins>Junxian He</ins>* , Pascale Fung  
EMNLP 2024.


**Compression Represents Intelligence Linearly**    
Yuzhen Huang\*, Jinghan Zhang\*, Zifei Shan, *<ins>Junxian He</ins>*  
COLM 2024. [[arxiv]](https://arxiv.org/abs/2404.09937) [[code]](https://github.com/hkust-nlp/llm-compression-intelligence)


**Prompt Optimization via Adversarial In-Context Learning**  
Xuan Long Do\*, Yiran Zhao\*, Hannah Brown\*, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, *<ins>Junxian He</ins>*  
ACL 2024. [[arxiv]](https://arxiv.org/abs/2312.02614)

**In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation**  
Shiqi Chen\*, Miao Xiong\*, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, *<ins>Junxian He</ins>*  
ICML 2024. [[arxiv]](https://arxiv.org/abs/2403.01548) [[code]](https://github.com/hkust-nlp/Activation_decoding)

**What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning**  
Wei Liu\*, Weihao Zeng\*, Keqing He, Yong Jiang, *<ins>Junxian He</ins>*  
ICLR 2024. [[arxiv]](https://arxiv.org/abs/2312.15685) [[github]](https://github.com/hkust-nlp/deita)

**Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs**  
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, *<ins>Junxian He</ins>*, Bryan Hooi  
ICLR 2024. [[arxiv]](https://arxiv.org/abs/2306.13063)

**K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization**  
Cheng Deng, Tianhang Zhang, Zhongmou He, Yi Xu, Qiyuan Chen, Yuanyuan Shi, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu Zhou, Zhouhan Lin, *<ins>Junxian He</ins>*  
WSDM 2024. [[arxiv]](https://arxiv.org/abs/2306.05064) [[github]](https://github.com/davendw49/k2)

**Composing Parameter-Efficient Modules with Arithmetic Operations**  
Jinghan Zhang, Shiqi Chen, Junteng Liu, *<ins>Junxian He</ins>*  
NeurIPS 2023. [[arxiv]](https://arxiv.org/abs/2306.14870) [[code]](https://github.com/hkust-nlp/PEM_composition)

**Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding**  
Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, *<ins>Junxian He</ins>*, Qizhe Xie  
NeurIPS 2023. [[arxiv]](https://arxiv.org/abs/2305.00633) [[code]](https://github.com/YuxiXie/SelfEval-Guided-Decoding)

**C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models**  
Yuzhen Huang\*, Yuzhuo Bai\*, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, *<ins>Junxian He</ins>*  
NeurIPS 2023 (Datasets and Benchmarks track). [[arxiv]](https://arxiv.org/abs/2305.08322) [[github]](https://github.com/hkust-nlp/ceval) [[website]](https://cevalbenchmark.com) [[dataset]](https://huggingface.co/datasets/ceval/ceval-exam)

**FELM: Benchmarking Factuality Evaluation of Large Language Models**  
Shiqi Chen, Yiran Zhao, Jinghan Zhang, I-Chun Chern, Siyang Gao, Pengfei Liu, *<ins>Junxian He</ins>*  
NeurIPS 2023 (Datasets and Benchmarks track). [[arxiv]](https://arxiv.org/abs/2310.00741) [[github]](https://github.com/hkust-nlp/felm) [[website]](https://hkust-nlp.github.io/felm/) [[dataset]](https://huggingface.co/datasets/hkust-nlp/felm)

**Contrastive Learning of Sentence Embeddings from Scratch**  
Junlei Zhang, Zhenzhong Lan, *<ins>Junxian He</ins>*  
EMNLP 2023. [[arxiv]](https://arxiv.org/abs/2305.15077)  [[code]](https://github.com/hkust-nlp/SynCSE)

**Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN**  
Fatemehsadat Mireshghallah, Nikolai Vogler, *<ins>Junxian He</ins>*, Omar Florez, Ahmed El-Kishky, Taylor Berg-Kirkpatrick  
EMNLP 2023. [[arxiv]](https://arxiv.org/abs/2209.05706)

**Automatic Model Selection with Large Language Models for Reasoning**  
Xu Zhao, Yuxi Xie, Kenji Kawaguchi, *<ins>Junxian He</ins>*, Qizhe Xie  
EMNLP 2023 Findings. [[arxiv]](https://arxiv.org/abs/2305.14333) [[code]](https://github.com/XuZhao0/Model-Selection-Reasoning)

**Mega: Moving Average Equipped Gated Attention**  
Xuezhe Ma\*, Chunting Zhou\*, Xiang Kong, *<ins>Junxian He</ins>*, Liangke Gui, Graham Neubig, Jonathan May, Luke Zettlemoyer  
ICLR 2023. [[arxiv]](https://arxiv.org/abs/2209.10655)

**CTRLsum: Towards Generic Controllable Text Summarization**  
*<ins>Junxian He</ins>*, Wojciech Kryściński, Bryan McCann, Nazneen Rajani, Caiming Xiong  
EMNLP 2022. [[arxiv]](https://arxiv.org/abs/2012.04281) [[code]](https://github.com/salesforce/ctrl-sum) [[huggingface demo]](https://huggingface.co/spaces/akhaliq/ctrl-sum) [[streamlit demo]](https://share.streamlit.io/jxhe/ctrlsum-demo/ctrlsum_demo.py)

**Prompt Consistency for Zero-Shot Task Generalization**  
Chunting Zhou\*, *<ins>Junxian He</ins>*\*, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig  
EMNLP 2022 Findings. [[arxiv]](https://arxiv.org/abs/2205.00049)

**Towards a Unified View of Parameter-Efficient Transfer Learning**  
*<ins>Junxian He</ins>*\*, Chunting Zhou*, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig   
ICLR 2022. [[OpenReview]](https://openreview.net/forum?id=0RDcd5Axok) [[arxiv]](http://arxiv.org/abs/2110.04366) [[code]](https://github.com/jxhe/unify-parameter-efficient-tuning)  
<span style="color:red"><i>Spotlight</i></span>

**Capturing Structural Locality in Non-parametric Language Models**  
Frank F. Xu, *<ins>Junxian He</ins>*, Graham Neubig, Vincent Josua Hellendoorn  
ICLR 2022. [[arxiv]](https://arxiv.org/abs/2110.02870)

**Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval**  
Uri Alon, Frank F. Xu, *<ins>Junxian He</ins>*, Sudipta Sengupta, Dan Roth, Graham Neubig  
ICML 2022. [[arxiv]](https://arxiv.org/abs/2201.12431) [[code]](https://github.com/neulab/retomaton)

**Efficient Nearest Neighbor Language Models**  
*<ins>Junxian He</ins>*, Graham Neubig, Taylor Berg-Kirkpatrick  
EMNLP 2021. [[arxiv]](https://arxiv.org/abs/2109.04212) [[code]](https://github.com/jxhe/efficient-knnlm)

**The Source-Target Domain Mismatch Problem in Machine Translation**  
Jiajun Shen, Peng-Jen Chen, Matthew Le, *<ins>Junxian He</ins>*, Jiatao Gu, Myle Ott, Michael Auli, Marc'Aurelio Ranzato  
EACL 2021. [[arxiv]](https://arxiv.org/abs/1909.13151)

**Dependency Induction Through the Lens of Visual Perception**  
Ruisi Su, Shruti Rijhwani, Hao Zhu, *<ins>Junxian He</ins>*, Xinyu Wang, Yonatan Bisk, Graham Neubig  
CoNLL 2021. [[arxiv]](https://arxiv.org/abs/2109.09790) [[code]](https://github.com/ruisi-su/concrete_dep)

**Learning Sparse Protoypes for Text Generation**  
*<ins>Junxian He</ins>*, Taylor Berg-Kirkpatrick, Graham Neubig  
NeurIPS 2020. [[arxiv]](https://arxiv.org/abs/2006.16336) [[code]](https://github.com/jxhe/sparse-text-prototype)

**Revisiting Self-Training for Neural Sequence Generation**  
*<ins>Junxian He</ins>*\*, Jiatao Gu*, Jiajun Shen, Marc'Aurelio Ranzato  
ICLR 2020. [[arxiv]](https://arxiv.org/abs/1909.13788) [[code]](https://github.com/jxhe/self-training-text-generation)

**A Probabilistic Formulation of Unsupervised Text Style Transfer**  
*<ins>Junxian He</ins>*\*, Xinyi Wang*, Graham Neubig, Taylor Berg-Kirkpatrick  
ICLR 2020. [[arxiv]](https://arxiv.org/abs/2002.03912) [[code]](https://github.com/cindyxinyiwang/deep-latent-sequence-model)  
<span style="color:red"><i>Spotlight</i></span>

**On the Sentence Embeddings from Pre-trained Language Models**  
Bohan Li, Hao Zhou, *<ins>Junxian He</ins>*, Mingxuan Wang, Yiming Yang, Lei Li  
EMNLP 2020. [[arxiv]](https://arxiv.org/abs/2011.05864) [[code]](https://github.com/bohanli/BERT-flow)

**A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text**  
Bohan Li\*, *<ins>Junxian He</ins>*\*, Graham Neubig, Taylor Berg-Kirkpatrick, Yiming Yang  
EMNLP 2019 (short paper). [[arxiv]](https://arxiv.org/abs/1909.00868) [[code]](https://github.com/bohanli/vae-pretraining-encoder)

**Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections**  
*<ins>Junxian He</ins>*, Zhisong Zhang, Taylor Berg-Kirkpatrick, Graham Neubig  
ACL 2019. [[arxiv]](https://arxiv.org/abs/1906.02656) [[code]](https://github.com/jxhe/cross-lingual-struct-flow)

**Texar: A modularized, versatile, and extensible toolkit for text generation**  
Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng Zhao, *<ins>Junxian He</ins>*, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan Liang, Wangrong Zhu, Devendra Singh Sachan, Eric P. Xing  
ACL 2019 (demo paper). <span style="color:red">Best demo paper nomination</span>. [[arxiv]](https://arxiv.org/abs/1809.00794) [[GitHub]](https://github.com/asyml/texar)

**Lagging Inference Networks and Posterior Collapse in Variational Autoencoders**  
*<ins>Junxian He</ins>*, Daniel Spokoyny, Graham Neubig, Taylor Berg-Kirkpatrick  
ICLR 2019. [[arxiv]](http://arxiv.org/abs/1901.05534) [[code]](https://github.com/jxhe/vae-lagging-encoder)

**Unsupervised Learning of Syntactic Structure with Invertible Neural Projections**   
*<ins>Junxian He</ins>*, Graham Neubig, Taylor Berg-Kirkpatrick  
EMNLP 2018. [[arxiv]](https://arxiv.org/abs/1808.09111) [[code]](https://github.com/jxhe/struct-learning-with-flow)

**StructVAE: Tree-structured Latent Variable Models for Semi-supervised Semantic Parsing**  
Pengcheng Yin, Chunting Zhou, *<ins>Junxian He</ins>*, Graham Neubig  
ACL 2018. [[arxiv]](https://arxiv.org/abs/1806.07832)

**Efficient Correlated Topic Modeling with Topic Embedding**  
*<ins>Junxian He</ins>*\*, Zhiting Hu*, Taylor Berg-Kirkpatrick, Ying Huang, Eric Xing  
KDD 2017. [[arxiv]](https://arxiv.org/abs/1707.00206)

**Text Network Exploration via Heterogeneous Web of Topics**  
*<ins>Junxian He</ins>*, Ying Huang, Changfeng Liu, Jiaming Shen, Yuting Jia, Xinbing Wang  
ICDM 2016 WorkShop. [[arxiv]](https://arxiv.org/abs/1610.00219) [[demo]]({{ site.baseurl }}/demo/TopicAtlas/CiteseerX.html) 
